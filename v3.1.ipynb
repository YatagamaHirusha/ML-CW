{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6bcc4a",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T08:57:43.164068Z",
     "start_time": "2026-02-27T08:57:43.158571Z"
    },
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 62,
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import deque"
   ],
   "id": "94609d6dcdb0eedb"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e473eac3b02ab1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T02:23:31.169506Z",
     "start_time": "2026-02-27T02:23:31.156141Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"updated_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca25864bc5f9d4",
   "metadata": {},
   "source": [
    "## Analyze and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8814222a7f71aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T04:13:56.091798Z",
     "start_time": "2026-02-27T04:13:56.080267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1201 entries, 0 to 1200\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   user_id                  1201 non-null   float64\n",
      " 1   name                     1200 non-null   str    \n",
      " 2   age                      1201 non-null   float64\n",
      " 3   gender                   1201 non-null   str    \n",
      " 4   target_gender            1201 non-null   str    \n",
      " 5   location                 1201 non-null   str    \n",
      " 6   occupation               1201 non-null   str    \n",
      " 7   anxiety                  1201 non-null   float64\n",
      " 8   avoidance                1201 non-null   float64\n",
      " 9   Lifestyle                1201 non-null   str    \n",
      " 10  Arts & Creativity        1201 non-null   str    \n",
      " 11  Music                    1201 non-null   str    \n",
      " 12  Movies & Shows           1201 non-null   str    \n",
      " 13  Intellectual & Learning  1201 non-null   str    \n",
      " 14  Food & Drinks            1201 non-null   str    \n",
      " 15  Sports & Outdoor         1201 non-null   str    \n",
      " 16  Gaming & Digital         1201 non-null   str    \n",
      " 17  Travel & Culture         1201 non-null   str    \n",
      " 18  Personality & Values     1201 non-null   str    \n",
      " 19  Relationship Intent      1201 non-null   str    \n",
      "dtypes: float64(4), str(16)\n",
      "memory usage: 187.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4b7b9e77a9bdb7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T02:25:47.313824Z",
     "start_time": "2026-02-27T02:25:47.301861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>target_gender</th>\n",
       "      <th>location</th>\n",
       "      <th>occupation</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>avoidance</th>\n",
       "      <th>Lifestyle</th>\n",
       "      <th>Arts &amp; Creativity</th>\n",
       "      <th>Music</th>\n",
       "      <th>Movies &amp; Shows</th>\n",
       "      <th>Intellectual &amp; Learning</th>\n",
       "      <th>Food &amp; Drinks</th>\n",
       "      <th>Sports &amp; Outdoor</th>\n",
       "      <th>Gaming &amp; Digital</th>\n",
       "      <th>Travel &amp; Culture</th>\n",
       "      <th>Personality &amp; Values</th>\n",
       "      <th>Relationship Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nethmi Bandara</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gampaha</td>\n",
       "      <td>Construction Worker</td>\n",
       "      <td>4.09</td>\n",
       "      <td>6.57</td>\n",
       "      <td>[\"Night Owl\", \"Meditation\"]</td>\n",
       "      <td>[\"Filmmaking\", \"Graphic Design\", \"Poetry\", \"In...</td>\n",
       "      <td>[\"Indie\"]</td>\n",
       "      <td>[\"Documentaries\", \"Horror\", \"Anime\", \"Sitcoms\"]</td>\n",
       "      <td>[\"Self-Improvement\"]</td>\n",
       "      <td>[\"Street Food\", \"Spicy Food\", \"Cooking\", \"Coff...</td>\n",
       "      <td>[\"Surfing\", \"Football\", \"Adventure Sports\"]</td>\n",
       "      <td>[\"Web3\", \"Crypto\"]</td>\n",
       "      <td>[\"Museums\", \"Beaches\", \"Mountains\", \"Cultural ...</td>\n",
       "      <td>[\"Atheist\", \"Feminist\"]</td>\n",
       "      <td>[\"Open Relationship\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Malith</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Kandy</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.88</td>\n",
       "      <td>[\"Traveling\", \"Vegan\", \"Digital Nomad\"]</td>\n",
       "      <td>[\"Interior Design\"]</td>\n",
       "      <td>[\"Singing\", \"K-Pop\", \"Rock\"]</td>\n",
       "      <td>[\"Horror\", \"Documentaries\", \"K-Dramas\"]</td>\n",
       "      <td>[\"Science\", \"Books &amp; Reading\", \"Self-Improveme...</td>\n",
       "      <td>[\"Street Food\", \"Spicy Food\", \"Craft Beer\", \"F...</td>\n",
       "      <td>[\"Cricket\", \"Swimming\", \"Hiking\", \"Surfing\"]</td>\n",
       "      <td>[\"Console Gaming\", \"Board Games\", \"Mobile Gami...</td>\n",
       "      <td>[\"Museums\", \"Languages\"]</td>\n",
       "      <td>[\"Feminist\", \"Family-Oriented\", \"Career-Focuse...</td>\n",
       "      <td>[\"Marriage\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Isuru</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gampaha</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>2.63</td>\n",
       "      <td>4.24</td>\n",
       "      <td>[\"Early Bird\"]</td>\n",
       "      <td>[\"Poetry\"]</td>\n",
       "      <td>[\"Hip-Hop\", \"EDM\"]</td>\n",
       "      <td>[\"Sci-Fi\"]</td>\n",
       "      <td>[\"Technology\", \"History\", \"Science\"]</td>\n",
       "      <td>[\"Coffee\", \"Cooking\", \"Baking\", \"Street Food\"]</td>\n",
       "      <td>[\"Surfing\", \"Cycling\", \"Swimming\", \"Football\"]</td>\n",
       "      <td>[\"Mobile Gaming\", \"Dungeons &amp; Dragons\"]</td>\n",
       "      <td>[\"Beaches\"]</td>\n",
       "      <td>[\"Career-Focused\", \"Family-Oriented\", \"Spiritu...</td>\n",
       "      <td>[\"Long-Term Relationship\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Hashan</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Badulla</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.37</td>\n",
       "      <td>[\"Pet Lover\", \"Meditation\", \"Vegan\"]</td>\n",
       "      <td>[\"Filmmaking\"]</td>\n",
       "      <td>[\"Rock\", \"EDM\", \"Singing\"]</td>\n",
       "      <td>[\"Horror\", \"Sci-Fi\"]</td>\n",
       "      <td>[\"History\", \"AI &amp; Machine Learning\", \"Technolo...</td>\n",
       "      <td>[\"Street Food\"]</td>\n",
       "      <td>[\"Basketball\", \"Hiking\", \"Surfing\", \"Cycling\"]</td>\n",
       "      <td>[\"VR\", \"Console Gaming\"]</td>\n",
       "      <td>[\"Cultural Festivals\", \"Backpacking\", \"Road Tr...</td>\n",
       "      <td>[\"Environmentalist\", \"Politically Active\"]</td>\n",
       "      <td>[\"Open Relationship\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Supun</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Kandy</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.17</td>\n",
       "      <td>[\"Traveling\", \"Pet Lover\"]</td>\n",
       "      <td>[\"Filmmaking\", \"Interior Design\", \"DIY &amp; Crafts\"]</td>\n",
       "      <td>[\"K-Pop\", \"Pop\"]</td>\n",
       "      <td>[\"Thriller\", \"Sitcoms\", \"Documentaries\"]</td>\n",
       "      <td>[\"Self-Improvement\", \"Psychology\"]</td>\n",
       "      <td>[\"Wine\", \"Baking\", \"Craft Beer\"]</td>\n",
       "      <td>[\"Hiking\", \"Basketball\", \"Surfing\", \"Camping\"]</td>\n",
       "      <td>[\"Board Games\", \"Console Gaming\", \"VR\"]</td>\n",
       "      <td>[\"Luxury Travel\", \"Museums\", \"Road Trips\"]</td>\n",
       "      <td>[\"Politically Active\", \"Spiritual\"]</td>\n",
       "      <td>[\"Casual Dating\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            name   age  gender target_gender location  \\\n",
       "0      1.0  Nethmi Bandara  37.0  Female          Male  Gampaha   \n",
       "1      2.0          Malith  32.0    Male        Female    Kandy   \n",
       "2      3.0           Isuru  25.0    Male        Female  Gampaha   \n",
       "3      4.0          Hashan  25.0    Male        Female  Badulla   \n",
       "4      5.0           Supun  23.0    Male        Female    Kandy   \n",
       "\n",
       "            occupation  anxiety  avoidance  \\\n",
       "0  Construction Worker     4.09       6.57   \n",
       "1           Accountant     3.96       4.88   \n",
       "2           Accountant     2.63       4.24   \n",
       "3           Accountant     4.67       1.37   \n",
       "4               Doctor     3.45       1.17   \n",
       "\n",
       "                                 Lifestyle  \\\n",
       "0              [\"Night Owl\", \"Meditation\"]   \n",
       "1  [\"Traveling\", \"Vegan\", \"Digital Nomad\"]   \n",
       "2                           [\"Early Bird\"]   \n",
       "3     [\"Pet Lover\", \"Meditation\", \"Vegan\"]   \n",
       "4               [\"Traveling\", \"Pet Lover\"]   \n",
       "\n",
       "                                   Arts & Creativity  \\\n",
       "0  [\"Filmmaking\", \"Graphic Design\", \"Poetry\", \"In...   \n",
       "1                                [\"Interior Design\"]   \n",
       "2                                         [\"Poetry\"]   \n",
       "3                                     [\"Filmmaking\"]   \n",
       "4  [\"Filmmaking\", \"Interior Design\", \"DIY & Crafts\"]   \n",
       "\n",
       "                          Music  \\\n",
       "0                     [\"Indie\"]   \n",
       "1  [\"Singing\", \"K-Pop\", \"Rock\"]   \n",
       "2            [\"Hip-Hop\", \"EDM\"]   \n",
       "3    [\"Rock\", \"EDM\", \"Singing\"]   \n",
       "4              [\"K-Pop\", \"Pop\"]   \n",
       "\n",
       "                                    Movies & Shows  \\\n",
       "0  [\"Documentaries\", \"Horror\", \"Anime\", \"Sitcoms\"]   \n",
       "1          [\"Horror\", \"Documentaries\", \"K-Dramas\"]   \n",
       "2                                       [\"Sci-Fi\"]   \n",
       "3                             [\"Horror\", \"Sci-Fi\"]   \n",
       "4         [\"Thriller\", \"Sitcoms\", \"Documentaries\"]   \n",
       "\n",
       "                             Intellectual & Learning  \\\n",
       "0                               [\"Self-Improvement\"]   \n",
       "1  [\"Science\", \"Books & Reading\", \"Self-Improveme...   \n",
       "2               [\"Technology\", \"History\", \"Science\"]   \n",
       "3  [\"History\", \"AI & Machine Learning\", \"Technolo...   \n",
       "4                 [\"Self-Improvement\", \"Psychology\"]   \n",
       "\n",
       "                                       Food & Drinks  \\\n",
       "0  [\"Street Food\", \"Spicy Food\", \"Cooking\", \"Coff...   \n",
       "1  [\"Street Food\", \"Spicy Food\", \"Craft Beer\", \"F...   \n",
       "2     [\"Coffee\", \"Cooking\", \"Baking\", \"Street Food\"]   \n",
       "3                                    [\"Street Food\"]   \n",
       "4                   [\"Wine\", \"Baking\", \"Craft Beer\"]   \n",
       "\n",
       "                                 Sports & Outdoor  \\\n",
       "0     [\"Surfing\", \"Football\", \"Adventure Sports\"]   \n",
       "1    [\"Cricket\", \"Swimming\", \"Hiking\", \"Surfing\"]   \n",
       "2  [\"Surfing\", \"Cycling\", \"Swimming\", \"Football\"]   \n",
       "3  [\"Basketball\", \"Hiking\", \"Surfing\", \"Cycling\"]   \n",
       "4  [\"Hiking\", \"Basketball\", \"Surfing\", \"Camping\"]   \n",
       "\n",
       "                                    Gaming & Digital  \\\n",
       "0                                 [\"Web3\", \"Crypto\"]   \n",
       "1  [\"Console Gaming\", \"Board Games\", \"Mobile Gami...   \n",
       "2            [\"Mobile Gaming\", \"Dungeons & Dragons\"]   \n",
       "3                           [\"VR\", \"Console Gaming\"]   \n",
       "4            [\"Board Games\", \"Console Gaming\", \"VR\"]   \n",
       "\n",
       "                                    Travel & Culture  \\\n",
       "0  [\"Museums\", \"Beaches\", \"Mountains\", \"Cultural ...   \n",
       "1                           [\"Museums\", \"Languages\"]   \n",
       "2                                        [\"Beaches\"]   \n",
       "3  [\"Cultural Festivals\", \"Backpacking\", \"Road Tr...   \n",
       "4         [\"Luxury Travel\", \"Museums\", \"Road Trips\"]   \n",
       "\n",
       "                                Personality & Values  \\\n",
       "0                            [\"Atheist\", \"Feminist\"]   \n",
       "1  [\"Feminist\", \"Family-Oriented\", \"Career-Focuse...   \n",
       "2  [\"Career-Focused\", \"Family-Oriented\", \"Spiritu...   \n",
       "3         [\"Environmentalist\", \"Politically Active\"]   \n",
       "4                [\"Politically Active\", \"Spiritual\"]   \n",
       "\n",
       "          Relationship Intent  \n",
       "0       [\"Open Relationship\"]  \n",
       "1                [\"Marriage\"]  \n",
       "2  [\"Long-Term Relationship\"]  \n",
       "3       [\"Open Relationship\"]  \n",
       "4           [\"Casual Dating\"]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c26f89a3626a047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T02:25:51.469387Z",
     "start_time": "2026-02-27T02:25:51.460032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>avoidance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>600.500000</td>\n",
       "      <td>28.810000</td>\n",
       "      <td>3.470083</td>\n",
       "      <td>3.484917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>346.554469</td>\n",
       "      <td>6.666403</td>\n",
       "      <td>1.392839</td>\n",
       "      <td>1.363520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300.750000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.507500</td>\n",
       "      <td>2.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>600.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>3.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>900.250000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>4.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id          age      anxiety    avoidance\n",
       "count  1200.000000  1200.000000  1200.000000  1200.000000\n",
       "mean    600.500000    28.810000     3.470083     3.484917\n",
       "std     346.554469     6.666403     1.392839     1.363520\n",
       "min       1.000000    18.000000     1.000000     1.000000\n",
       "25%     300.750000    23.000000     2.507500     2.497500\n",
       "50%     600.500000    29.000000     3.380000     3.485000\n",
       "75%     900.250000    35.000000     4.410000     4.410000\n",
       "max    1200.000000    40.000000     7.000000     7.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d9457e26255e250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T02:26:04.981265Z",
     "start_time": "2026-02-27T02:26:04.974382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                    11\n",
       "name                        0\n",
       "age                        11\n",
       "gender                     11\n",
       "target_gender              11\n",
       "location                   11\n",
       "occupation                 11\n",
       "anxiety                    11\n",
       "avoidance                  11\n",
       "Lifestyle                  11\n",
       "Arts & Creativity          11\n",
       "Music                      11\n",
       "Movies & Shows             11\n",
       "Intellectual & Learning    11\n",
       "Food & Drinks              11\n",
       "Sports & Outdoor           11\n",
       "Gaming & Digital           11\n",
       "Travel & Culture           11\n",
       "Personality & Values       11\n",
       "Relationship Intent        11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65e21def156ec953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T04:24:25.711585Z",
     "start_time": "2026-02-27T04:24:25.697580Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "df.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fab46b12515faef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T04:24:27.071219Z",
     "start_time": "2026-02-27T04:24:27.058775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>target_gender</th>\n",
       "      <th>location</th>\n",
       "      <th>occupation</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>avoidance</th>\n",
       "      <th>Lifestyle</th>\n",
       "      <th>Arts &amp; Creativity</th>\n",
       "      <th>Music</th>\n",
       "      <th>Movies &amp; Shows</th>\n",
       "      <th>Intellectual &amp; Learning</th>\n",
       "      <th>Food &amp; Drinks</th>\n",
       "      <th>Sports &amp; Outdoor</th>\n",
       "      <th>Gaming &amp; Digital</th>\n",
       "      <th>Travel &amp; Culture</th>\n",
       "      <th>Personality &amp; Values</th>\n",
       "      <th>Relationship Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1196.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>Driver</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.84</td>\n",
       "      <td>[\"Vegan\", \"Night Owl\"]</td>\n",
       "      <td>[\"Writing\", \"Painting\", \"Filmmaking\", \"Interio...</td>\n",
       "      <td>[\"Classical\", \"EDM\", \"Rock\", \"Pop\"]</td>\n",
       "      <td>[\"Horror\", \"Anime\", \"Documentaries\"]</td>\n",
       "      <td>[\"Psychology\"]</td>\n",
       "      <td>[\"Fine Dining\", \"Baking\"]</td>\n",
       "      <td>[\"Hiking\", \"Camping\"]</td>\n",
       "      <td>[\"Web3\"]</td>\n",
       "      <td>[\"Backpacking\", \"Cultural Festivals\", \"Road Tr...</td>\n",
       "      <td>[\"Family-Oriented\", \"Spiritual\", \"Feminist\", \"...</td>\n",
       "      <td>[\"Marriage\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1197.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.23</td>\n",
       "      <td>[\"Vegetarian\", \"Night Owl\"]</td>\n",
       "      <td>[\"Interior Design\", \"Graphic Design\", \"Poetry\"...</td>\n",
       "      <td>[\"Playing Instruments\"]</td>\n",
       "      <td>[\"Romance\", \"Documentaries\", \"Sci-Fi\"]</td>\n",
       "      <td>[\"Psychology\", \"Books &amp; Reading\", \"AI &amp; Machin...</td>\n",
       "      <td>[\"Street Food\", \"Baking\"]</td>\n",
       "      <td>[\"Cycling\"]</td>\n",
       "      <td>[\"Console Gaming\", \"Crypto\"]</td>\n",
       "      <td>[\"Languages\", \"Mountains\", \"Beaches\"]</td>\n",
       "      <td>[\"Atheist\", \"Spiritual\", \"Family-Oriented\", \"C...</td>\n",
       "      <td>[\"Casual Dating\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1198.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ratnapura</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>4.29</td>\n",
       "      <td>2.50</td>\n",
       "      <td>[\"Early Bird\", \"Pet Lover\"]</td>\n",
       "      <td>[\"Poetry\", \"Painting\"]</td>\n",
       "      <td>[\"Singing\"]</td>\n",
       "      <td>[\"Sitcoms\", \"K-Dramas\", \"Romance\", \"Thriller\"]</td>\n",
       "      <td>[\"Philosophy\"]</td>\n",
       "      <td>[\"Spicy Food\", \"Cooking\", \"Fine Dining\", \"Baki...</td>\n",
       "      <td>[\"Cricket\", \"Football\", \"Camping\", \"Basketball\"]</td>\n",
       "      <td>[\"Dungeons &amp; Dragons\", \"eSports\", \"Board Games...</td>\n",
       "      <td>[\"Mountains\"]</td>\n",
       "      <td>[\"Religious\", \"Family-Oriented\", \"Career-Focus...</td>\n",
       "      <td>[\"Marriage\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1199.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Badulla</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.58</td>\n",
       "      <td>[\"Vegan\", \"Gym\", \"Vegetarian\", \"Fitness\"]</td>\n",
       "      <td>[\"Graphic Design\", \"Interior Design\"]</td>\n",
       "      <td>[\"EDM\", \"Hip-Hop\", \"Jazz\"]</td>\n",
       "      <td>[\"K-Dramas\"]</td>\n",
       "      <td>[\"Books &amp; Reading\"]</td>\n",
       "      <td>[\"Fine Dining\", \"Street Food\"]</td>\n",
       "      <td>[\"Cricket\"]</td>\n",
       "      <td>[\"Mobile Gaming\", \"Board Games\", \"eSports\"]</td>\n",
       "      <td>[\"Museums\", \"Languages\", \"Road Trips\"]</td>\n",
       "      <td>[\"Family-Oriented\", \"Spiritual\", \"Career-Focus...</td>\n",
       "      <td>[\"Long-Term Relationship\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Monaragala</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.33</td>\n",
       "      <td>[\"Fitness\", \"Night Owl\"]</td>\n",
       "      <td>[\"Fashion\"]</td>\n",
       "      <td>[\"EDM\", \"Pop\", \"Playing Instruments\", \"Hip-Hop\"]</td>\n",
       "      <td>[\"Thriller\", \"Anime\", \"K-Dramas\", \"Documentari...</td>\n",
       "      <td>[\"Self-Improvement\"]</td>\n",
       "      <td>[\"Baking\", \"Cooking\"]</td>\n",
       "      <td>[\"Adventure Sports\", \"Swimming\", \"Basketball\"]</td>\n",
       "      <td>[\"Dungeons &amp; Dragons\"]</td>\n",
       "      <td>[\"Museums\", \"Beaches\", \"Mountains\"]</td>\n",
       "      <td>[\"Atheist\", \"Politically Active\"]</td>\n",
       "      <td>[\"Still Figuring It Out\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id   age  gender target_gender    location      occupation  \\\n",
       "1195   1196.0  39.0    Male        Female     Colombo          Driver   \n",
       "1196   1197.0  27.0    Male        Female     Colombo          Doctor   \n",
       "1197   1198.0  33.0    Male        Female   Ratnapura          Doctor   \n",
       "1198   1199.0  32.0  Female          Male     Badulla  Business Owner   \n",
       "1199   1200.0  28.0  Female          Male  Monaragala          Farmer   \n",
       "\n",
       "      anxiety  avoidance                                  Lifestyle  \\\n",
       "1195     2.37       1.84                     [\"Vegan\", \"Night Owl\"]   \n",
       "1196     1.73       4.23                [\"Vegetarian\", \"Night Owl\"]   \n",
       "1197     4.29       2.50                [\"Early Bird\", \"Pet Lover\"]   \n",
       "1198     3.53       3.58  [\"Vegan\", \"Gym\", \"Vegetarian\", \"Fitness\"]   \n",
       "1199     6.05       6.33                   [\"Fitness\", \"Night Owl\"]   \n",
       "\n",
       "                                      Arts & Creativity  \\\n",
       "1195  [\"Writing\", \"Painting\", \"Filmmaking\", \"Interio...   \n",
       "1196  [\"Interior Design\", \"Graphic Design\", \"Poetry\"...   \n",
       "1197                             [\"Poetry\", \"Painting\"]   \n",
       "1198              [\"Graphic Design\", \"Interior Design\"]   \n",
       "1199                                        [\"Fashion\"]   \n",
       "\n",
       "                                                 Music  \\\n",
       "1195               [\"Classical\", \"EDM\", \"Rock\", \"Pop\"]   \n",
       "1196                           [\"Playing Instruments\"]   \n",
       "1197                                       [\"Singing\"]   \n",
       "1198                        [\"EDM\", \"Hip-Hop\", \"Jazz\"]   \n",
       "1199  [\"EDM\", \"Pop\", \"Playing Instruments\", \"Hip-Hop\"]   \n",
       "\n",
       "                                         Movies & Shows  \\\n",
       "1195               [\"Horror\", \"Anime\", \"Documentaries\"]   \n",
       "1196             [\"Romance\", \"Documentaries\", \"Sci-Fi\"]   \n",
       "1197     [\"Sitcoms\", \"K-Dramas\", \"Romance\", \"Thriller\"]   \n",
       "1198                                       [\"K-Dramas\"]   \n",
       "1199  [\"Thriller\", \"Anime\", \"K-Dramas\", \"Documentari...   \n",
       "\n",
       "                                Intellectual & Learning  \\\n",
       "1195                                     [\"Psychology\"]   \n",
       "1196  [\"Psychology\", \"Books & Reading\", \"AI & Machin...   \n",
       "1197                                     [\"Philosophy\"]   \n",
       "1198                                [\"Books & Reading\"]   \n",
       "1199                               [\"Self-Improvement\"]   \n",
       "\n",
       "                                          Food & Drinks  \\\n",
       "1195                          [\"Fine Dining\", \"Baking\"]   \n",
       "1196                          [\"Street Food\", \"Baking\"]   \n",
       "1197  [\"Spicy Food\", \"Cooking\", \"Fine Dining\", \"Baki...   \n",
       "1198                     [\"Fine Dining\", \"Street Food\"]   \n",
       "1199                              [\"Baking\", \"Cooking\"]   \n",
       "\n",
       "                                      Sports & Outdoor  \\\n",
       "1195                             [\"Hiking\", \"Camping\"]   \n",
       "1196                                       [\"Cycling\"]   \n",
       "1197  [\"Cricket\", \"Football\", \"Camping\", \"Basketball\"]   \n",
       "1198                                       [\"Cricket\"]   \n",
       "1199    [\"Adventure Sports\", \"Swimming\", \"Basketball\"]   \n",
       "\n",
       "                                       Gaming & Digital  \\\n",
       "1195                                           [\"Web3\"]   \n",
       "1196                       [\"Console Gaming\", \"Crypto\"]   \n",
       "1197  [\"Dungeons & Dragons\", \"eSports\", \"Board Games...   \n",
       "1198        [\"Mobile Gaming\", \"Board Games\", \"eSports\"]   \n",
       "1199                             [\"Dungeons & Dragons\"]   \n",
       "\n",
       "                                       Travel & Culture  \\\n",
       "1195  [\"Backpacking\", \"Cultural Festivals\", \"Road Tr...   \n",
       "1196              [\"Languages\", \"Mountains\", \"Beaches\"]   \n",
       "1197                                      [\"Mountains\"]   \n",
       "1198             [\"Museums\", \"Languages\", \"Road Trips\"]   \n",
       "1199                [\"Museums\", \"Beaches\", \"Mountains\"]   \n",
       "\n",
       "                                   Personality & Values  \\\n",
       "1195  [\"Family-Oriented\", \"Spiritual\", \"Feminist\", \"...   \n",
       "1196  [\"Atheist\", \"Spiritual\", \"Family-Oriented\", \"C...   \n",
       "1197  [\"Religious\", \"Family-Oriented\", \"Career-Focus...   \n",
       "1198  [\"Family-Oriented\", \"Spiritual\", \"Career-Focus...   \n",
       "1199                  [\"Atheist\", \"Politically Active\"]   \n",
       "\n",
       "             Relationship Intent  \n",
       "1195                [\"Marriage\"]  \n",
       "1196           [\"Casual Dating\"]  \n",
       "1197                [\"Marriage\"]  \n",
       "1198  [\"Long-Term Relationship\"]  \n",
       "1199   [\"Still Figuring It Out\"]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40393f69b5c3f4c9",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Reward System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7a89d7e2191322a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T05:39:06.101242Z",
     "start_time": "2026-02-27T05:39:06.086180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Confirm/Skip Simulator...\n",
      "Result: The user hit SKIP! (-1 Reward)\n"
     ]
    }
   ],
   "source": [
    "# We assign strict weights to the 12 categories.\n",
    "# The RL Agent must learn these priorities organically through trial and error.\n",
    "CATEGORY_WEIGHTS = {\n",
    "    \"Relationship Intent\": 40.0,   # Dealbreaker\n",
    "    \"Personality & Values\": 20.0,  # High impact on stability\n",
    "    \"Lifestyle\": 15.0,             # Day-to-day friction\n",
    "    \"Intellectual & Learning\": 5.0,\n",
    "    \"Food & Drinks\": 5.0,\n",
    "    \"Travel & Culture\": 5.0,\n",
    "    \"Gaming & Digital\": 5.0,\n",
    "    \"Sports & Outdoor\": 5.0,\n",
    "    \"Arts & Creativity\": 3.0,\n",
    "    \"Music\": 2.0,\n",
    "    \"Movies & Shows\": 2.0\n",
    "}\n",
    "# Total max category points = 107.0\n",
    "\n",
    "# --- THE MATH TRANSLATORS (Step 2) ---\n",
    "\n",
    "def calculate_jaccard(list_a, list_b):\n",
    "    \"\"\"Calculates the percentage overlap between two lists of text (0.0 to 1.0)\"\"\"\n",
    "    set_a, set_b = set(list_a), set(list_b)\n",
    "    intersection = len(set_a.intersection(set_b))\n",
    "    union = len(set_a.union(set_b))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def process_pair(user_a, user_b):\n",
    "    \"\"\"\n",
    "    Takes two raw user rows and returns:\n",
    "    1. The State Tensor (What the Neural Network sees)\n",
    "    2. The Reward (How we score the Neural Network's choice)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Base Logic Constraints (Hard fails)\n",
    "    # If gender preferences or locations don't match, immediate negative reward.\n",
    "    if user_a['target_gender'] != user_b['gender'] or user_b['target_gender'] != user_a['gender']:\n",
    "        return None, -100.0 # Terrible guess by the Agent\n",
    "\n",
    "    if user_a['location'] != user_b['location']:\n",
    "        return None, -50.0  # Long distance penalty\n",
    "\n",
    "    # 2. Calculate the 11 Category Overlaps\n",
    "    category_overlaps = {}\n",
    "    reward_from_interests = 0.0\n",
    "\n",
    "    for cat, weight in CATEGORY_WEIGHTS.items():\n",
    "        # Parse the JSON strings back into Python lists\n",
    "        items_a = json.loads(user_a[cat])\n",
    "        items_b = json.loads(user_b[cat])\n",
    "\n",
    "        # Calculate overlap (0.0 to 1.0)\n",
    "        overlap = calculate_jaccard(items_a, items_b)\n",
    "        category_overlaps[cat] = overlap\n",
    "\n",
    "        # Add to the Agent's reward\n",
    "        reward_from_interests += (overlap * weight)\n",
    "\n",
    "    # 3. Calculate Psychological Reward (The Core Logic)\n",
    "    # Reward stability, penalize the Anxious-Avoidant trap\n",
    "    anx_gap = abs(user_a['anxiety'] - user_b['anxiety'])\n",
    "    avo_gap = abs(user_a['avoidance'] - user_b['avoidance'])\n",
    "    trap_metric = (user_a['anxiety'] * user_b['avoidance']) + (user_b['anxiety'] * user_a['avoidance'])\n",
    "\n",
    "    psych_reward = 50.0 # Base psychological score\n",
    "    if trap_metric > 35: psych_reward -= 40.0 # Huge penalty for toxic trap\n",
    "    if user_a['anxiety'] < 3.0 and user_b['anxiety'] < 3.0: psych_reward += 20.0 # Secure bonus\n",
    "\n",
    "    # Final Reward Calculation\n",
    "    total_reward = reward_from_interests + psych_reward\n",
    "\n",
    "    # 4. Build the State Vector (The Neural Network Input)\n",
    "    # This is a flat array of numbers representing this specific couple\n",
    "    state_vector = [\n",
    "        abs(user_a['age'] - user_b['age']) / 10.0, # Normalized age gap\n",
    "        user_a['anxiety'] / 7.0,                   # Normalize to 0-1\n",
    "        user_a['avoidance'] / 7.0,\n",
    "        user_b['anxiety'] / 7.0,\n",
    "        user_b['avoidance'] / 7.0,\n",
    "    ]\n",
    "\n",
    "    # Append the 11 overlap scores to the state\n",
    "    for cat in CATEGORY_WEIGHTS.keys():\n",
    "        state_vector.append(category_overlaps[cat])\n",
    "\n",
    "    # state_vector is now an array of 16 numbers (5 base + 11 categories)\n",
    "    return np.array(state_vector), total_reward\n",
    "\n",
    "\n",
    "def simulate_user_interaction(user_a, candidate_b):\n",
    "    \"\"\"\n",
    "    The HIDDEN Environment Simulator.\n",
    "    Simulates if User A will 'Confirm' or 'Skip' Candidate B based on hidden psychology.\n",
    "    \"\"\"\n",
    "    # 1. Calculate the hidden mathematical score (The Agent won't see this score anymore!)\n",
    "    state_vector, hidden_score = process_pair(user_a, candidate_b)\n",
    "\n",
    "    # Hard mismatches (Gender/Location) result in an automatic Skip\n",
    "    if state_vector is None:\n",
    "        return None, -1.0 # Reward is -1.0 (SKIP)\n",
    "\n",
    "    # 2. Convert the hidden score into a Probability of Confirming (0.0 to 1.0)\n",
    "    # Assuming ~120 was a great score in our old system.\n",
    "    base_probability = hidden_score / 120.0\n",
    "\n",
    "    # Cap probability at 95% (Even perfect matches sometimes get skipped)\n",
    "    # Floor it at 5% (Even bad matches sometimes get confirmed by accident)\n",
    "    confirm_probability = np.clip(base_probability, 0.05, 0.95)\n",
    "\n",
    "    # 3. The Stochastic Action (Roll the Dice)\n",
    "    dice_roll = random.random()\n",
    "\n",
    "    if dice_roll <= confirm_probability:\n",
    "        reward = 1.0  # CONFIRM (+1 Reward)\n",
    "    else:\n",
    "        reward = -1.0 # SKIP (-1 Reward)\n",
    "\n",
    "    return state_vector, reward\n",
    "\n",
    "# --- TEST THE SIMULATOR ---\n",
    "print(\"Testing the Confirm/Skip Simulator...\")\n",
    "state, simulated_reward = simulate_user_interaction(df.iloc[0], df.iloc[1])\n",
    "\n",
    "if simulated_reward == 1.0:\n",
    "    print(\"Result: The user hit CONFIRM! (+1 Reward)\")\n",
    "else:\n",
    "    print(\"Result: The user hit SKIP! (-1 Reward)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb6dc0ac20b8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b1506f4dd70405",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c52adeeedc79ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T08:58:21.572463Z",
     "start_time": "2026-02-27T08:58:03.601704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting True DQN Training with Experience Replay for 5000 Epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/my95xtr12b36m3_q51pptlf40000gn/T/ipykernel_59525/795476195.py:99: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  scheduler.step()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000] | Epsilon: 0.61 | LR: 0.00100 | Recent Reward Avg: 0.17\n",
      "Epoch [1000/5000] | Epsilon: 0.37 | LR: 0.00100 | Recent Reward Avg: 0.37\n",
      "Epoch [1500/5000] | Epsilon: 0.22 | LR: 0.00050 | Recent Reward Avg: 0.36\n",
      "Epoch [2000/5000] | Epsilon: 0.14 | LR: 0.00050 | Recent Reward Avg: 0.48\n",
      "Epoch [2500/5000] | Epsilon: 0.08 | LR: 0.00050 | Recent Reward Avg: 0.50\n",
      "Epoch [3000/5000] | Epsilon: 0.05 | LR: 0.00025 | Recent Reward Avg: 0.50\n",
      "Epoch [3500/5000] | Epsilon: 0.05 | LR: 0.00025 | Recent Reward Avg: 0.51\n",
      "Epoch [4000/5000] | Epsilon: 0.05 | LR: 0.00025 | Recent Reward Avg: 0.50\n",
      "Epoch [4500/5000] | Epsilon: 0.05 | LR: 0.00013 | Recent Reward Avg: 0.50\n",
      "Epoch [5000/5000] | Epsilon: 0.05 | LR: 0.00013 | Recent Reward Avg: 0.54\n",
      "\n",
      "Training Complete! You officially built a Deep Q-Network with Experience Replay.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. UPDATED NEURAL NETWORK (16 FEATURES) ---\n",
    "class MatchmakerDQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MatchmakerDQN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(16, 128),  # Fixed input to 16 features!\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize Agent, Optimizer, and the new LR Scheduler\n",
    "agent = MatchmakerDQN().to(device)\n",
    "optimizer = optim.Adam(agent.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=1500, gamma=0.5) # Cuts learning rate in half every 1500 epochs\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- 2. THE EXPERIENCE REPLAY BUFFER ---\n",
    "memory = deque(maxlen=10000) # The Agent remembers its last 10,000 matches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# --- 3. UPDATED HYPERPARAMETERS ---\n",
    "EPOCHS = 5000\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.999 # Slower decay: hits 0.05 around epoch 3000 instead of 1500\n",
    "epsilon_min = 0.05\n",
    "\n",
    "print(f\"Starting True DQN Training with Experience Replay for {EPOCHS} Epochs...\")\n",
    "\n",
    "agent.train()\n",
    "reward_tracking = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1. App Session Simulation\n",
    "    target_idx = random.randint(0, len(df) - 1)\n",
    "    target_user = df.iloc[target_idx]\n",
    "\n",
    "    candidates = df[\n",
    "        (df['user_id'] != target_user['user_id']) &\n",
    "        (df['gender'] == target_user['target_gender']) &\n",
    "        (df['target_gender'] == target_user['gender']) &\n",
    "        (df['location'] == target_user['location'])\n",
    "    ]\n",
    "    if len(candidates) == 0: continue\n",
    "\n",
    "    feed_candidates = candidates.sample(min(10, len(candidates)))\n",
    "    feed_states, valid_cands = [], []\n",
    "\n",
    "    for _, cand in feed_candidates.iterrows():\n",
    "        state, _ = process_pair(target_user, cand)\n",
    "        if state is not None:\n",
    "            feed_states.append(state)\n",
    "            valid_cands.append(cand)\n",
    "\n",
    "    if not feed_states: continue\n",
    "    state_tensors = torch.FloatTensor(np.array(feed_states)).to(device)\n",
    "\n",
    "    # 2. Epsilon-Greedy Action (Explore vs Exploit)\n",
    "    if random.random() < epsilon:\n",
    "        chosen_idx = random.randint(0, len(feed_states) - 1)\n",
    "    else:\n",
    "        with torch.no_grad(): # Don't calculate gradients just for picking an action\n",
    "            q_values = agent(state_tensors)\n",
    "            chosen_idx = torch.argmax(q_values).item()\n",
    "\n",
    "    chosen_candidate = valid_cands[chosen_idx]\n",
    "\n",
    "    # 3. Environment Interaction (Simulator)\n",
    "    _, actual_reward = simulate_user_interaction(target_user, chosen_candidate)\n",
    "    reward_tracking.append(actual_reward)\n",
    "\n",
    "    # --- 4. SAVE TO EXPERIENCE REPLAY ---\n",
    "    # Store the tuple: (State, Reward)\n",
    "    memory.append((feed_states[chosen_idx], actual_reward))\n",
    "\n",
    "    # --- 5. THE DQN LEARNING MAGIC (Batch Training) ---\n",
    "    # Only learn if we have enough memories to form a batch\n",
    "    if len(memory) >= BATCH_SIZE:\n",
    "        minibatch = random.sample(memory, BATCH_SIZE)\n",
    "\n",
    "        batch_states = torch.FloatTensor(np.array([m[0] for m in minibatch])).to(device)\n",
    "        batch_rewards = torch.FloatTensor([[m[1]] for m in minibatch]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_q_values = agent(batch_states)\n",
    "        loss = criterion(predicted_q_values, batch_rewards)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 6. Step the Learning Rate Scheduler & Epsilon\n",
    "    scheduler.step()\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        recent_win_rate = (sum(reward_tracking[-500:]) / 500)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] | Epsilon: {epsilon:.2f} | LR: {scheduler.get_last_lr()[0]:.5f} | Recent Reward Avg: {recent_win_rate:.2f}\")\n",
    "\n",
    "print(\"\\nTraining Complete! You officially built a Deep Q-Network with Experience Replay.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8bc23a46bc084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74d39f5aa13fca59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T07:12:50.855495Z",
     "start_time": "2026-02-27T07:12:34.244781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running True RL Evaluation over 500 simulated sessions...\n",
      "\n",
      "--------------------------------------------------\n",
      "üèÜ TRUE RL EVALUATION (Confirm Rate %) üèÜ\n",
      "--------------------------------------------------\n",
      "1. DRL Agent:      92.8% Confirm Rate\n",
      "2. Hobby Baseline: 82.4% Confirm Rate\n",
      "3. Random Guesser: 53.6% Confirm Rate\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rl_model(environment_df, trained_agent, num_trials=500):\n",
    "    print(f\"Running True RL Evaluation over {num_trials} simulated sessions...\\n\")\n",
    "\n",
    "    trained_agent.eval() # Inference mode (no exploring, purely exploiting)\n",
    "\n",
    "    agent_confirms = 0\n",
    "    hobby_confirms = 0\n",
    "    random_confirms = 0\n",
    "\n",
    "    valid_trials = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_trials):\n",
    "            target_idx = random.randint(0, len(environment_df) - 1)\n",
    "            target_user = environment_df.iloc[target_idx]\n",
    "\n",
    "            candidates = environment_df[\n",
    "                (environment_df['user_id'] != target_user['user_id']) &\n",
    "                (environment_df['gender'] == target_user['target_gender']) &\n",
    "                (environment_df['target_gender'] == target_user['gender']) &\n",
    "                (environment_df['location'] == target_user['location'])\n",
    "            ]\n",
    "\n",
    "            if len(candidates) == 0: continue\n",
    "            valid_trials += 1\n",
    "\n",
    "            agent_scores = []\n",
    "            hobby_scores = []\n",
    "            valid_candidate_list = []\n",
    "\n",
    "            # 1. Rank all candidates\n",
    "            for idx, cand in candidates.iterrows():\n",
    "                state_vector, _ = process_pair(target_user, cand)\n",
    "\n",
    "                if state_vector is not None:\n",
    "                    valid_candidate_list.append(cand)\n",
    "\n",
    "                    # Agent predicts Q-Value (Expected Reward)\n",
    "                    state_tensor = torch.FloatTensor(state_vector).to(device)\n",
    "                    q_val = trained_agent(state_tensor).item()\n",
    "                    agent_scores.append(q_val)\n",
    "\n",
    "                    # Hobby Baseline calculates Jaccard sum\n",
    "                    hobby_overlap = sum(state_vector[5:])\n",
    "                    hobby_scores.append(hobby_overlap)\n",
    "\n",
    "            if not valid_candidate_list: continue\n",
    "\n",
    "            # 2. Each strategy picks its absolute #1 Candidate\n",
    "            agent_best_idx = np.argmax(agent_scores)\n",
    "            hobby_best_idx = np.argmax(hobby_scores)\n",
    "            random_best_idx = random.randint(0, len(valid_candidate_list) - 1)\n",
    "\n",
    "            # 3. Expose picks to the Stochastic Environment (Did the user hit Confirm?)\n",
    "            _, agent_reward = simulate_user_interaction(target_user, valid_candidate_list[agent_best_idx])\n",
    "            _, hobby_reward = simulate_user_interaction(target_user, valid_candidate_list[hobby_best_idx])\n",
    "            _, random_reward = simulate_user_interaction(target_user, valid_candidate_list[random_best_idx])\n",
    "\n",
    "            # 4. Tally the Confirms (+1.0)\n",
    "            if agent_reward == 1.0: agent_confirms += 1\n",
    "            if hobby_reward == 1.0: hobby_confirms += 1\n",
    "            if random_reward == 1.0: random_confirms += 1\n",
    "\n",
    "    # Calculate Win Rates\n",
    "    agent_win_rate = (agent_confirms / valid_trials) * 100\n",
    "    hobby_win_rate = (hobby_confirms / valid_trials) * 100\n",
    "    random_win_rate = (random_confirms / valid_trials) * 100\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"üèÜ TRUE RL EVALUATION (Confirm Rate %) üèÜ\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"1. DRL Agent:      {agent_win_rate:.1f}% Confirm Rate\")\n",
    "    print(f\"2. Hobby Baseline: {hobby_win_rate:.1f}% Confirm Rate\")\n",
    "    print(f\"3. Random Guesser: {random_win_rate:.1f}% Confirm Rate\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Run the stochastic evaluation\n",
    "evaluate_rl_model(df, agent, num_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe7879f5cf8136",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45452d92061e24f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T05:58:19.872846Z",
     "start_time": "2026-02-27T05:58:19.804678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding matches.......\n",
      "Stage 1 Complete: Filtered down to 47 viable candidates.\n",
      "\n",
      "--- NEW TOP 5 MATCHES ---\n",
      "#1 | User 667.0 | Construction Worker  | Score: 0.78 | Anx: 3.8, Avo: 5.1\n",
      "#2 | User 86.0 | Bank Officer         | Score: 0.73 | Anx: 3.2, Avo: 4.4\n",
      "#3 | User 246.0 | Pharmacist           | Score: 0.73 | Anx: 2.8, Avo: 4.9\n",
      "#4 | User 583.0 | Marketing Executive  | Score: 0.73 | Anx: 3.6, Avo: 6.6\n",
      "#5 | User 864.0 | Bank Officer         | Score: 0.72 | Anx: 1.0, Avo: 4.0\n"
     ]
    }
   ],
   "source": [
    "def find_best_matches(target_user_id, environment_df, trained_agent, top_n=5):\n",
    "    \"\"\"\n",
    "    Takes a single user, filters the database, scores candidates using the AI,\n",
    "    and returns the best matches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch the PyTorch model from 'Training' to 'Evaluation' mode\n",
    "    # This turns off Dropout and optimizes for speed\n",
    "    trained_agent.eval()\n",
    "\n",
    "    # Get the target user's profile\n",
    "    target_user = environment_df[environment_df['user_id'] == target_user_id].iloc[0]\n",
    "    print(f\"Finding matches.......\")\n",
    "\n",
    "    # STAGE 1: Candidate Generation (Database Hard Filters)\n",
    "    # We drop the 1,000+ users down to a smaller pool to save computational power\n",
    "    candidates = environment_df[\n",
    "        (environment_df['user_id'] != target_user_id) &\n",
    "        (environment_df['gender'] == target_user['target_gender']) &\n",
    "        (environment_df['target_gender'] == target_user['gender']) &\n",
    "        (environment_df['location'] == target_user['location']) # Must be in the same city\n",
    "    ]\n",
    "\n",
    "    print(f\"Stage 1 Complete: Filtered down to {len(candidates)} viable candidates.\")\n",
    "\n",
    "    match_predictions = []\n",
    "\n",
    "    # STAGE 2: Precision Ranking (The DRL Agent)\n",
    "    # torch.no_grad() tells PyTorch NOT to calculate gradients (saves massive memory)\n",
    "    with torch.no_grad():\n",
    "        for index, candidate in candidates.iterrows():\n",
    "            # Process the pair into the 16-feature State Tensor\n",
    "            state_vector, _ = process_pair(target_user, candidate)\n",
    "\n",
    "            if state_vector is not None:\n",
    "                # Convert to Tensor and send to GPU\n",
    "                state_tensor = torch.FloatTensor(state_vector).to(device)\n",
    "\n",
    "                # The Agent predicts the Q-Value (Expected Reward)\n",
    "                predicted_score = trained_agent(state_tensor).item()\n",
    "\n",
    "                match_predictions.append({\n",
    "                    'candidate_id': candidate['user_id'],\n",
    "                    'occupation': candidate['occupation'],\n",
    "                    'anxiety': candidate['anxiety'],\n",
    "                    'avoidance': candidate['avoidance'],\n",
    "                    'predicted_score': predicted_score\n",
    "                })\n",
    "\n",
    "    # Sort the results by the Agent's predicted score (Highest to Lowest)\n",
    "    match_predictions.sort(key=lambda x: x['predicted_score'], reverse=True)\n",
    "\n",
    "    return match_predictions[:top_n]\n",
    "\n",
    "\n",
    "# 1. DELETE ANY EXISTING USER 9999 TO PREVENT DUPLICATES\n",
    "df = df[df['user_id'] != 9999]\n",
    "\n",
    "# 2. CREATE THE FIXED USER (Matching your database strings exactly)\n",
    "test_user = {\n",
    "    'user_id': 9999,\n",
    "    'age': 23,\n",
    "    'gender': 'Male',\n",
    "    'target_gender': 'Female',\n",
    "    'location': 'Galle',\n",
    "    'occupation': 'Software Engineer',\n",
    "    'anxiety': 1.5,\n",
    "    'avoidance': 1.2,\n",
    "    'Relationship Intent': json.dumps(['Long-Term Relationship']), # The Fix\n",
    "    'Gaming & Digital': json.dumps(['PC Gaming', 'Game Dev']),\n",
    "    'Intellectual & Learning': json.dumps(['Technology', 'Science']),\n",
    "    'Personality & Values': json.dumps(['Logic-Driven', 'Honesty']),\n",
    "    'Lifestyle': json.dumps(['Night Owl', 'Digital Nomad']),\n",
    "    'Music': json.dumps(['EDM', 'Indie']),\n",
    "    'Movies & Shows': json.dumps(['Sci-Fi']),\n",
    "    'Food & Drinks': json.dumps(['Coffee Enthusiast']),\n",
    "    'Sports & Outdoor': json.dumps(['Gym']),\n",
    "    'Travel & Culture': json.dumps(['Backpacking']),\n",
    "    'Arts & Creativity': json.dumps(['Creative Writing'])\n",
    "}\n",
    "\n",
    "# 3. INJECT THE FRESH USER\n",
    "df = pd.concat([df, pd.DataFrame([test_user])], ignore_index=True)\n",
    "\n",
    "# 4. RE-RUN THE MATCHMAKER\n",
    "top_matches = find_best_matches(target_user_id=9999, environment_df=df, trained_agent=agent, top_n=5)\n",
    "\n",
    "print(\"\\n--- NEW TOP 5 MATCHES ---\")\n",
    "for i, match in enumerate(top_matches):\n",
    "    print(f\"#{i+1} | User {match['candidate_id']:<4} | {match['occupation']:<20} | Score: {match['predicted_score']:.2f} | Anx: {match['anxiety']:.1f}, Avo: {match['avoidance']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa286a10986114d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acde4bffe50ac27a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d6b0a0d827aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the True RL model\n",
    "rl_model_path = 'matchmind_true_rl_agent.pth'\n",
    "\n",
    "# Save the model's internal state\n",
    "torch.save(agent.state_dict(), rl_model_path)\n",
    "\n",
    "print(f\"True RL Model secured! Option B saved to: {rl_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c368391991dc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc0a909866a100e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849f4dea528561f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T06:59:20.761723Z",
     "start_time": "2026-02-27T06:58:40.196148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold User-Level Cross Validation for RL Agent...\n",
      "\n",
      "--- FOLD 1/5 ---\n",
      "Fold 1 Unseen Confirm Rate: 82.5%\n",
      "\n",
      "--- FOLD 2/5 ---\n",
      "Fold 2 Unseen Confirm Rate: 77.5%\n",
      "\n",
      "--- FOLD 3/5 ---\n",
      "Fold 3 Unseen Confirm Rate: 81.0%\n",
      "\n",
      "--- FOLD 4/5 ---\n",
      "Fold 4 Unseen Confirm Rate: 83.5%\n",
      "\n",
      "--- FOLD 5/5 ---\n",
      "Fold 5 Unseen Confirm Rate: 80.5%\n",
      "\n",
      "========================================\n",
      "FINAL CROSS-VALIDATION RESULTS (5 Folds)\n",
      "========================================\n",
      "Fold 1: 82.5%\n",
      "Fold 2: 77.5%\n",
      "Fold 3: 81.0%\n",
      "Fold 4: 83.5%\n",
      "Fold 5: 80.5%\n",
      "----------------------------------------\n",
      "Average Generalization Confirm Rate: 81.0%\n",
      "Standard Deviation (Stability):      ¬±2.0%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5-Fold User-Level Cross-Validation with Experience Replay\n",
    "# ============================================================\n",
    "# This mirrors the main training loop exactly:\n",
    "# - Experience Replay Buffer (deque, batch sampling)\n",
    "# - StepLR Learning Rate Scheduler\n",
    "# - Slower epsilon decay (0.999)\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS_PER_FOLD = 2000\n",
    "NUM_SPLITS = 5\n",
    "EVAL_TRIALS = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "unique_users = df['user_id'].unique()\n",
    "kf = KFold(n_splits=NUM_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "cv_confirm_rates = []\n",
    "\n",
    "print(f\"Starting {NUM_SPLITS}-Fold User-Level Cross Validation (with Experience Replay)...\\n\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_users)):\n",
    "    print(f\"--- FOLD {fold + 1}/{NUM_SPLITS} ---\")\n",
    "\n",
    "    # 1. Split the Environment (Users)\n",
    "    train_users = unique_users[train_idx]\n",
    "    test_users = unique_users[test_idx]\n",
    "\n",
    "    df_train = df[df['user_id'].isin(train_users)]\n",
    "    df_test = df[df['user_id'].isin(test_users)]\n",
    "\n",
    "    # 2. Initialize a FRESH Agent, Optimizer, Scheduler, and Replay Buffer\n",
    "    cv_agent = MatchmakerDQN().to(device)\n",
    "    optimizer = optim.Adam(cv_agent.parameters(), lr=0.001)\n",
    "    scheduler = StepLR(optimizer, step_size=600, gamma=0.5)  # Adjusted for 2000 epochs per fold\n",
    "    criterion = nn.MSELoss()\n",
    "    cv_memory = deque(maxlen=10000)\n",
    "\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.999  # Slower decay to match main training\n",
    "    epsilon_min = 0.05\n",
    "\n",
    "    # 3. TRAIN on the Train Environment (df_train) with Experience Replay\n",
    "    cv_agent.train()\n",
    "    for epoch in range(EPOCHS_PER_FOLD):\n",
    "        target_idx = random.randint(0, len(df_train) - 1)\n",
    "        target_user = df_train.iloc[target_idx]\n",
    "\n",
    "        candidates = df_train[\n",
    "            (df_train['user_id'] != target_user['user_id']) &\n",
    "            (df_train['gender'] == target_user['target_gender']) &\n",
    "            (df_train['target_gender'] == target_user['gender']) &\n",
    "            (df_train['location'] == target_user['location'])\n",
    "        ]\n",
    "\n",
    "        if len(candidates) == 0: continue\n",
    "\n",
    "        feed_candidates = candidates.sample(min(10, len(candidates)))\n",
    "        feed_states, valid_cands = [], []\n",
    "\n",
    "        for _, cand in feed_candidates.iterrows():\n",
    "            state, _ = process_pair(target_user, cand)\n",
    "            if state is not None:\n",
    "                feed_states.append(state)\n",
    "                valid_cands.append(cand)\n",
    "\n",
    "        if not feed_states: continue\n",
    "\n",
    "        state_tensors = torch.FloatTensor(np.array(feed_states)).to(device)\n",
    "\n",
    "        # Epsilon-Greedy Action\n",
    "        if random.random() < epsilon:\n",
    "            chosen_idx = random.randint(0, len(feed_states) - 1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = cv_agent(state_tensors)\n",
    "                chosen_idx = torch.argmax(q_values).item()\n",
    "\n",
    "        chosen_cand = valid_cands[chosen_idx]\n",
    "\n",
    "        # Environment Feedback\n",
    "        _, actual_reward = simulate_user_interaction(target_user, chosen_cand)\n",
    "\n",
    "        # Store in Experience Replay Buffer\n",
    "        cv_memory.append((feed_states[chosen_idx], actual_reward))\n",
    "\n",
    "        # Batch Learning from Replay Buffer\n",
    "        if len(cv_memory) >= BATCH_SIZE:\n",
    "            minibatch = random.sample(cv_memory, BATCH_SIZE)\n",
    "            batch_states = torch.FloatTensor(np.array([m[0] for m in minibatch])).to(device)\n",
    "            batch_rewards = torch.FloatTensor([[m[1]] for m in minibatch]).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_q = cv_agent(batch_states)\n",
    "            loss = criterion(predicted_q, batch_rewards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Step scheduler and decay epsilon\n",
    "        scheduler.step()\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "    # 4. EVALUATE on the Unseen Test Environment (df_test)\n",
    "    cv_agent.eval()\n",
    "    agent_confirms = 0\n",
    "    valid_evals = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(EVAL_TRIALS):\n",
    "            target_idx = random.randint(0, len(df_test) - 1)\n",
    "            target_user = df_test.iloc[target_idx]\n",
    "\n",
    "            candidates = df_test[\n",
    "                (df_test['user_id'] != target_user['user_id']) &\n",
    "                (df_test['gender'] == target_user['target_gender']) &\n",
    "                (df_test['target_gender'] == target_user['gender']) &\n",
    "                (df_test['location'] == target_user['location'])\n",
    "            ]\n",
    "\n",
    "            if len(candidates) == 0: continue\n",
    "            valid_evals += 1\n",
    "\n",
    "            agent_scores = []\n",
    "            valid_eval_cands = []\n",
    "\n",
    "            for _, cand in candidates.iterrows():\n",
    "                state_vector, _ = process_pair(target_user, cand)\n",
    "                if state_vector is not None:\n",
    "                    valid_eval_cands.append(cand)\n",
    "                    state_tensor = torch.FloatTensor(state_vector).to(device)\n",
    "                    agent_scores.append(cv_agent(state_tensor).item())\n",
    "\n",
    "            if not valid_eval_cands: continue\n",
    "\n",
    "            best_idx = np.argmax(agent_scores)\n",
    "            _, reward = simulate_user_interaction(target_user, valid_eval_cands[best_idx])\n",
    "\n",
    "            if reward == 1.0: agent_confirms += 1\n",
    "\n",
    "    # Record the Win Rate for this fold\n",
    "    win_rate = (agent_confirms / valid_evals) * 100 if valid_evals > 0 else 0\n",
    "    cv_confirm_rates.append(win_rate)\n",
    "    print(f\"Fold {fold + 1} Unseen Confirm Rate: {win_rate:.1f}%\\n\")\n",
    "\n",
    "# Final Cross-Validated Metrics\n",
    "print(\"=\" * 40)\n",
    "print(f\"FINAL CROSS-VALIDATION RESULTS (5 Folds)\")\n",
    "print(\"=\" * 40)\n",
    "for i, rate in enumerate(cv_confirm_rates):\n",
    "    print(f\"Fold {i+1}: {rate:.1f}%\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Average Generalization Confirm Rate: {np.mean(cv_confirm_rates):.1f}%\")\n",
    "print(f\"Standard Deviation (Stability):      +/-{np.std(cv_confirm_rates):.1f}%\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db713a6e5543cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
